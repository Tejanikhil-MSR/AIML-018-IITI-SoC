{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathway as pw\n",
    "from pathway.xpacks.llm.parsers import UnstructuredParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files table schema :  <pathway.Table schema={'data': <class 'bytes'>}>\n",
      "Documents table schema :  <pathway.Table schema={'elements': list[tuple[str, pathway.internals.json.Json]]}>\n"
     ]
    }
   ],
   "source": [
    "files = pw.io.fs.read(\n",
    "    path = \"../Data/Summarized_PDFs/\",\n",
    "    mode=\"streaming\",\n",
    "    format=\"binary\",\n",
    "    autocommit_duration_ms=50,\n",
    ")\n",
    "\n",
    "print(\"Files table schema : \", files)\n",
    "\n",
    "parser = UnstructuredParser(chunking_mode=\"elements\")\n",
    "# Unstructured library accepts the documents in the raw binary format and returns the text\n",
    "documents = files.select(elements=parser(pw.this.data))\n",
    "# TokenCountSplitter returns data in the same format as UnstructuredParser - that is for each row it returns a list of tuples, where each tuple consists of a string with the text of a chunk and a dictionary with associated metadata.\n",
    "print(\"Documents table schema : \", documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before Flattening** :\n",
    "\n",
    "| id | elements         |\n",
    "| -- | ---------------- |\n",
    "| 1  | \\[\"a\", \"b\", \"c\"] |\n",
    "| 2  | \\[\"d\", \"e\"]      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document schema after flattening :  <pathway.Table schema={'elements': tuple[str, pathway.internals.json.Json]}>\n"
     ]
    }
   ],
   "source": [
    "documents = documents.flatten(pw.this.elements) # flatten list into multiple rows\n",
    "print(\"Document schema after flattening : \", documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After flattening** : \n",
    "\n",
    "| id | elements |\n",
    "| -- | -------- |\n",
    "| 1  | \"a\"      |\n",
    "| 1  | \"b\"      |\n",
    "| 1  | \"c\"      |\n",
    "| 2  | \"d\"      |\n",
    "| 2  | \"e\"      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined Documents schema :  <pathway.Table schema={'text': <class 'str'>, 'metadata': <class 'pathway.internals.json.Json'>}>\n"
     ]
    }
   ],
   "source": [
    "documents = documents.select(text=pw.this.elements[0], metadata=pw.this.elements[1]) # extract text and metadata from tuple\n",
    "print(\"Refined Documents schema : \", documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of the document table after splitting:  <pathway.Table schema={'chunk': list[tuple[str, pathway.internals.json.Json]]}>\n"
     ]
    }
   ],
   "source": [
    "from pathway.xpacks.llm.splitters import TokenCountSplitter\n",
    "\n",
    "splitter = TokenCountSplitter(min_tokens=100, max_tokens=300)\n",
    "texts = documents.select(chunk=splitter(pw.this.text))\n",
    "print(\"Schema of the document table after splitting: \", texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy to get more accurate retrieval : **Reranking**\n",
    "\n",
    "**Reference** : https://pathway.com/developers/user-guide/llm-xpack/overview#rerankers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iiti-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
